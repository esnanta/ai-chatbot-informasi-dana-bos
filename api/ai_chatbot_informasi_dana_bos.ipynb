{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "159daeb6c3804bbe9d37422606c5e070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38a54785e3d849c9921c696f800bf324",
              "IPY_MODEL_30f3b2731ad44cbab8861519960c3d63",
              "IPY_MODEL_737f13417d974ad0a074a214c70b7bb1"
            ],
            "layout": "IPY_MODEL_af4d1a7d12264c5fa27d583cecba547d"
          }
        },
        "38a54785e3d849c9921c696f800bf324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73bb8a7dcc0a47b789d6677ec17c4555",
            "placeholder": "​",
            "style": "IPY_MODEL_37ce58a897f445be9892eb607ce910d4",
            "value": "Batches: 100%"
          }
        },
        "30f3b2731ad44cbab8861519960c3d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63f7fbd175db4f35a389ce253fde38f1",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf1548d138684c28bdcb4b279ecde25a",
            "value": 5
          }
        },
        "737f13417d974ad0a074a214c70b7bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57339734286c456f8118156ae1afc705",
            "placeholder": "​",
            "style": "IPY_MODEL_bcf77ce65a414683b8313e5fb0a56d13",
            "value": " 5/5 [00:45&lt;00:00,  5.02s/it]"
          }
        },
        "af4d1a7d12264c5fa27d583cecba547d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73bb8a7dcc0a47b789d6677ec17c4555": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37ce58a897f445be9892eb607ce910d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63f7fbd175db4f35a389ce253fde38f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf1548d138684c28bdcb4b279ecde25a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57339734286c456f8118156ae1afc705": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcf77ce65a414683b8313e5fb0a56d13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "1. This system that relies on semantic similarity. It finds the text in the document that is most similar to the user's question.\n",
        "2. If the user's question doesn't closely resemble the way the information is expressed in the document, the system may not find the correct answer.\n",
        "3. Basic Functionality covers:\n",
        "    * Extract text from PDF documents.\n",
        "    * Perform semantic search to find relevant chunks of text.\n",
        "    * Clean the output to remove unwanted content.\n",
        "    * Provide an answer to the user's question (even if the answer is not always perfect).\n",
        "\n"
      ],
      "metadata": {
        "id": "B9lCgwJuNeHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further Development\n",
        "1. Clarifying Expectation, example :\n",
        "    * Chatbot: \"Dana BOS digunakan untuk membiayai kegiatan operasional sekolah. Apakah Anda ingin mengetahui contoh kegiatan operasional yang dapat dibiayai oleh Dana BOS?\"\n",
        "2. Provide a list of example questions that the user can ask. This shows them the types of questions the chatbot is good at answering. Example:\n",
        "    * Apa saja syarat pengajuan Dana BOS?\n",
        "    * Bagaimana cara melaporkan penggunaan Dana BOS?\n",
        "    * Sebutkan contoh kegiatan yang dapat dibiayai oleh Dana BOS.\n",
        "3. Keyword Suggestions: As the user types their question, suggest relevant keywords that they can include to make their question more specific.\n",
        "4. Intent Recognition (Advanced): Implement a simple intent recognition system. This would analyze the user's question and try to identify the intent behind it (e.g., \"find allowed uses,\" \"find reporting requirements\"). Based on the intent, the chatbot could automatically rephrase the question to be more targeted. This requires more advanced natural language processing techniques.\n",
        "5. Expand the Training Data (If Possible): If you have the ability to add more data to the system, try to find documents that explicitly list the allowed uses of Dana BOS in a clear and structured way. This will make it easier for the semantic search to find the right information.\n",
        "6. Hybrid Approach (Advanced): Consider combining this semantic search approach with a more traditional keyword-based search. If the semantic search fails to find a good answer, the chatbot could fall back to a keyword search to find any relevant documents and present them to the user."
      ],
      "metadata": {
        "id": "1uA6_DXcA7dk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Library"
      ],
      "metadata": {
        "id": "uMo4iKw2NpWv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omTDcRywLsNw",
        "outputId": "be3cfd3a-7ac3-4da5-ac91-411cc94454f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Collecting sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sastrawi, pymupdf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pymupdf-1.25.4 sastrawi-1.0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install pymupdf nltk sastrawi transformers sentence-transformers\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import fitz\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from google.colab import drive\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Download resource NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Gathering"
      ],
      "metadata": {
        "id": "8SFcHCpwORjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Gathering\n",
        "# ===============================\n",
        "# 1. MOUNT GOOGLE DRIVE & CEK FILES\n",
        "# ===============================\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path ke direktori penyimpanan file PDF\n",
        "pdf_dir = \"/content/drive/My Drive/Colab Notebooks/AI Chatbot Berbasis Regulasi\"\n",
        "\n",
        "# Cek apakah direktori ada\n",
        "if not os.path.exists(pdf_dir):\n",
        "    raise FileNotFoundError(f\"Direktori {pdf_dir} tidak ditemukan! Periksa kembali path-nya.\")\n",
        "else:\n",
        "    print(f\"Direktori ditemukan! Daftar file PDF: {os.listdir(pdf_dir)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUAjLu-hOUiX",
        "outputId": "33255dac-f642-4c54-a798-948a45e3114b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Direktori ditemukan! Daftar file PDF: ['Permendikbudriset No. 63 Tahun 2023.pdf', 'Untitled folder', 'chunks.json', 'embeddings.npy', 'cleaned_texts.json']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 2. EKSTRAKSI TEKS DARI FILE PDF\n",
        "# ===============================\n",
        "\n",
        "# --- PDF Text Extraction ---\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text(\"text\") + \"\\n\"\n",
        "    return text.strip()\n",
        "\n",
        "pdf_files = [f for f in os.listdir(pdf_dir) if f.endswith(\".pdf\")]\n",
        "pdf_texts = {}\n",
        "\n",
        "for pdf_file in pdf_files:\n",
        "    pdf_path = os.path.join(pdf_dir, pdf_file)\n",
        "    try:\n",
        "        text = extract_text_from_pdf(pdf_path)\n",
        "        pdf_texts[pdf_file] = text\n",
        "        print(f\"Extracted text from: {pdf_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from {pdf_file}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFfX2D-2Qfsf",
        "outputId": "f13988c3-e5b0-49db-df09-48f70a99978c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted text from: Permendikbudriset No. 63 Tahun 2023.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Data"
      ],
      "metadata": {
        "id": "AQ-aw2LwUTW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 3. PREPROCESSING TEKS\n",
        "# ===============================\n",
        "\n",
        "def clean_text(text):\n",
        "\n",
        "    # This collapses multiple consecutive blank lines into a single blank line,\n",
        "    # reducing unnecessary whitespace.\n",
        "    text = re.sub(r'\\n+', '\\n', text)\n",
        "\n",
        "    # replaces sequences of spaces, tabs, or newlines with a single space,\n",
        "    # ensuring consistent spacing\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # This line finds instances like \"Pasal 17.\" and replaces them with\n",
        "    # \"Pasal 17 \". It removes the dot after the number and ensures\n",
        "    # there is space. This prevents the sentence tokenizer from incorrectly\n",
        "    # splitting \"Pasal 17.\" into two sentences. It's important to keep\n",
        "    # \"Pasal 17\" together as a single unit.\n",
        "    text = re.sub(r'Pasal (\\d+)\\.\\s', r'Pasal \\1 ', text)\n",
        "\n",
        "    # Remove dot, KEEP contents of parentheses\n",
        "    text = re.sub(r'Ayat \\((\\d+[a-z]?)\\)\\.\\s', r'Ayat (\\1) ', text)\n",
        "\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text, flags=re.IGNORECASE)  # Remove URLs\n",
        "    text = re.sub(r'jdih\\.kemdikbud\\.go\\.id', '', text, flags=re.IGNORECASE)  # Remove specific website\n",
        "\n",
        "    # Replace page number pattern '- 4 -' with '(page 4)'\n",
        "    text = re.sub(r'\\s-\\s(\\d+)\\s-\\s', r' (page \\1) ', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "cleaned_texts = {pdf: clean_text(text) for pdf, text in pdf_texts.items()}"
      ],
      "metadata": {
        "id": "KHaUz08k3Fbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 4. CHUNKING TEKS\n",
        "# Splits text into smaller chunks.\n",
        "# ===============================\n",
        "\n",
        "def chunk_text(text, chunk_size=100):\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    for sentence in sentences:\n",
        "        if len(current_chunk) + len(sentence) + 1 <= chunk_size:\n",
        "            current_chunk += sentence + \" \"\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence + \" \"\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "    return chunks\n",
        "\n",
        "all_chunks = []\n",
        "for pdf, text in cleaned_texts.items():\n",
        "    chunks = chunk_text(text)\n",
        "    all_chunks.extend(chunks)\n",
        "\n",
        "print(f\"Total chunks: {len(all_chunks)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka9AdmeJHERa",
        "outputId": "ff712e9c-d771-404f-d40a-0175dd01a063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks: 144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TOKENISASI TEKS"
      ],
      "metadata": {
        "id": "_TRngQpOU0vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 5. TOKENISASI TEKS & EMBEDDING\n",
        "# ===============================\n",
        "\n",
        "# Load Sentence Transformer model (multilingual)\n",
        "model_name = 'paraphrase-multilingual-mpnet-base-v2'  # Replace with the actual model\n",
        "model = SentenceTransformer(model_name)\n",
        "\n",
        "# Generate embeddings for the chunks\n",
        "embeddings = model.encode(all_chunks, show_progress_bar=True)"
      ],
      "metadata": {
        "id": "PL7UayJwU2Za",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "159daeb6c3804bbe9d37422606c5e070",
            "38a54785e3d849c9921c696f800bf324",
            "30f3b2731ad44cbab8861519960c3d63",
            "737f13417d974ad0a074a214c70b7bb1",
            "af4d1a7d12264c5fa27d583cecba547d",
            "73bb8a7dcc0a47b789d6677ec17c4555",
            "37ce58a897f445be9892eb607ce910d4",
            "63f7fbd175db4f35a389ce253fde38f1",
            "cf1548d138684c28bdcb4b279ecde25a",
            "57339734286c456f8118156ae1afc705",
            "bcf77ce65a414683b8313e5fb0a56d13"
          ]
        },
        "outputId": "58b7fa3c-7e30-4ff5-b40e-66a5b921d7a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "159daeb6c3804bbe9d37422606c5e070"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SAVING DATA"
      ],
      "metadata": {
        "id": "tNdrpdq1VEse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 6. SAVING DATA\n",
        "# ===============================\n",
        "\n",
        "# Define file paths for saving data\n",
        "embeddings_file = os.path.join(pdf_dir, \"embeddings.npy\")  # Path to save embeddings\n",
        "chunks_file = os.path.join(pdf_dir, \"chunks.json\")  # Path to save chunks\n",
        "cleaned_texts_file = os.path.join(pdf_dir, \"cleaned_texts.json\") # Path to save cleaned texts\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 1. Saving the SentenceTransformer Model (NOT NECESSARY, SEE COMMENTS)\n",
        "# ------------------------------------------------------------------\n",
        "# As discussed, saving the SentenceTransformer model itself is not necessary\n",
        "# because you can simply load it from the Hugging Face Model Hub using the model_name.\n",
        "# Saving the model weights would take up a lot of space and is not required in this case.\n",
        "\n",
        "# --------------------------------------\n",
        "# 2. Saving the Embeddings\n",
        "# --------------------------------------\n",
        "try:\n",
        "    np.save(embeddings_file, embeddings)\n",
        "    print(f\"Embeddings saved to: {embeddings_file}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving embeddings: {e}\")\n",
        "\n",
        "# --------------------------------------\n",
        "# 3. Saving the Chunks of Text\n",
        "# --------------------------------------\n",
        "try:\n",
        "    with open(chunks_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(all_chunks, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"Chunks saved to: {chunks_file}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving chunks: {e}\")\n",
        "\n",
        "# --------------------------------------\n",
        "# 4. Saving the Cleaned PDF Texts\n",
        "# --------------------------------------\n",
        "try:\n",
        "    with open(cleaned_texts_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(cleaned_texts, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"Cleaned texts saved to: {cleaned_texts_file}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving cleaned texts: {e}\")"
      ],
      "metadata": {
        "id": "xCHxhNuqVGav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0527d204-b39c-402a-a07e-f73b9ada4e4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings saved to: /content/drive/My Drive/Colab Notebooks/AI Chatbot Berbasis Regulasi/embeddings.npy\n",
            "Chunks saved to: /content/drive/My Drive/Colab Notebooks/AI Chatbot Berbasis Regulasi/chunks.json\n",
            "Cleaned texts saved to: /content/drive/My Drive/Colab Notebooks/AI Chatbot Berbasis Regulasi/cleaned_texts.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING"
      ],
      "metadata": {
        "id": "jZ1hT4h7fCl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 7. TESTING CHATBOT\n",
        "# ===============================\n",
        "\n",
        "# --- Question Answering ---\n",
        "def answer_question(question, embeddings, chunks, top_n=3):\n",
        "    question_embedding = model.encode([question])[0]\n",
        "    similarities = cosine_similarity([question_embedding], embeddings)[0]\n",
        "    top_indices = np.argsort(similarities)[::-1][:top_n]\n",
        "\n",
        "    # Debugging: Print the top chunks\n",
        "    print(\"Top Chunks before post-processing:\")\n",
        "    for i in top_indices:\n",
        "        print(f\"Chunk {i}: {chunks[i]}\\n---\")\n",
        "\n",
        "    context = \"\\n\".join([chunks[i] for i in top_indices])\n",
        "\n",
        "    return context\n",
        "\n",
        "def post_process_answer(answer):\n",
        "    # Split the answer into sentences\n",
        "    sentences = sent_tokenize(answer)\n",
        "\n",
        "    # Create a bulleted list from the sentences\n",
        "    bulleted_list = \"\\n\".join([f\"* {sentence.strip()}\" for sentence in sentences])\n",
        "\n",
        "    return bulleted_list\n",
        "\n",
        "# --- Example Usage ---\n",
        "question = \"Apakah Dana BOSP dapat digunakan untuk pengembangan sumber daya manusia?\"  # More focused question\n",
        "raw_answer = answer_question(question, embeddings, all_chunks, top_n=3)\n",
        "processed_answer = post_process_answer(raw_answer)\n",
        "\n",
        "print(f\"Pertanyaan: {question}\")\n",
        "print(f\"Jawaban:\\n{processed_answer}\")\n",
        "\n",
        "# --- Example Usage ---\n",
        "question = \"Untuk apa saja Dana BOS Kinerja dapat digunakan?\"  # More focused question\n",
        "raw_answer = answer_question(question, embeddings, all_chunks, top_n=3)\n",
        "processed_answer = post_process_answer(raw_answer)\n",
        "\n",
        "print(f\"Pertanyaan: {question}\")\n",
        "print(f\"Jawaban:\\n{processed_answer}\")\n",
        "\n",
        "# --- Example Usage ---\n",
        "question = \"Kapan laporan realisasi penggunaan Dana BOSP harus disampaikan?\"  # More focused question\n",
        "raw_answer = answer_question(question, embeddings, all_chunks, top_n=3)\n",
        "processed_answer = post_process_answer(raw_answer)\n",
        "\n",
        "print(f\"Pertanyaan: {question}\")\n",
        "print(f\"Jawaban:\\n{processed_answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAASzWSmey1I",
        "outputId": "f33ffdca-933d-4bcc-9ed7-e1801cfce603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Chunks before post-processing:\n",
            "Chunk 123: Rincian Komponen Penggunaan Dana BOS Kinerja Sekolah yang Melaksanakan Program Sekolah Penggerak a. Pengembangan sumber daya manusia merupakan komponen yang digunakan untuk pembiayaan dalam kegiatan penguatan sumber daya manusia dalam rangka pelaksanaan Program Sekolah Penggerak, seperti: 1) identifikasi, pemetaan potensi dan kebutuhan pelatihan; 2) penguatan pelatihan griyaan (in house training) di Satuan Pendidikan; 3) penguatan komunitas belajar bagi kepala Satuan Pendidikan dan pendidik; 4) pelatihan bersama komunitas belajar; 5) pelaksanaan diskusi terpumpun bersama dengan guru SD kelas awal; 6) peningkatan kapasitas literasi digital; dan/ atau 7) kegiatan lainnya yang relevan dalam rangka pelaksanaan pengembangan sumber daya manusia.\n",
            "---\n",
            "Chunk 19: Dana Bantuan Operasional Penyelenggaraan Pendidikan Kesetaraan yang selanjutnya disebut Dana BOP Kesetaraan adalah Dana BOSP untuk operasional Satuan Pendidikan dalam menyelenggarakan pendidikan kesetaraan.\n",
            "---\n",
            "Chunk 13: Dana Bantuan Operasional Satuan Pendidikan yang selanjutnya disebut Dana BOSP adalah dana alokasi khusus nonfisik untuk mendukung biaya operasional nonpersonalia bagi Satuan Pendidikan.\n",
            "---\n",
            "Pertanyaan: Apakah Dana BOSP dapat digunakan untuk pengembangan sumber daya manusia?\n",
            "Jawaban:\n",
            "* Rincian Komponen Penggunaan Dana BOS Kinerja Sekolah yang Melaksanakan Program Sekolah Penggerak a. Pengembangan sumber daya manusia merupakan komponen yang digunakan untuk pembiayaan dalam kegiatan penguatan sumber daya manusia dalam rangka pelaksanaan Program Sekolah Penggerak, seperti: 1) identifikasi, pemetaan potensi dan kebutuhan pelatihan; 2) penguatan pelatihan griyaan (in house training) di Satuan Pendidikan; 3) penguatan komunitas belajar bagi kepala Satuan Pendidikan dan pendidik; 4) pelatihan bersama komunitas belajar; 5) pelaksanaan diskusi terpumpun bersama dengan guru SD kelas awal; 6) peningkatan kapasitas literasi digital; dan/ atau 7) kegiatan lainnya yang relevan dalam rangka pelaksanaan pengembangan sumber daya manusia.\n",
            "* Dana Bantuan Operasional Penyelenggaraan Pendidikan Kesetaraan yang selanjutnya disebut Dana BOP Kesetaraan adalah Dana BOSP untuk operasional Satuan Pendidikan dalam menyelenggarakan pendidikan kesetaraan.\n",
            "* Dana Bantuan Operasional Satuan Pendidikan yang selanjutnya disebut Dana BOSP adalah dana alokasi khusus nonfisik untuk mendukung biaya operasional nonpersonalia bagi Satuan Pendidikan.\n",
            "Top Chunks before post-processing:\n",
            "Chunk 76: (2) Dana BOS sebagaimana dimaksud pada ayat (1) terdiri atas: a. Dana BOS Reguler; dan b. Dana BOS Kinerja.\n",
            "---\n",
            "Chunk 28: Dana Bantuan Operasional Sekolah Kinerja yang selanjutnya disebut Dana BOS Kinerja adalah Dana BOS yang digunakan untuk peningkatan mutu pendidikan Satuan Pendidikan yang menyelenggarakan pendidikan dasar dan pendidikan menengah yang dinilai berkinerja baik.\n",
            "---\n",
            "Chunk 13: Dana Bantuan Operasional Satuan Pendidikan yang selanjutnya disebut Dana BOSP adalah dana alokasi khusus nonfisik untuk mendukung biaya operasional nonpersonalia bagi Satuan Pendidikan.\n",
            "---\n",
            "Pertanyaan: Untuk apa saja Dana BOS Kinerja dapat digunakan?\n",
            "Jawaban:\n",
            "* (2) Dana BOS sebagaimana dimaksud pada ayat (1) terdiri atas: a. Dana BOS Reguler; dan b. Dana BOS Kinerja.\n",
            "* Dana Bantuan Operasional Sekolah Kinerja yang selanjutnya disebut Dana BOS Kinerja adalah Dana BOS yang digunakan untuk peningkatan mutu pendidikan Satuan Pendidikan yang menyelenggarakan pendidikan dasar dan pendidikan menengah yang dinilai berkinerja baik.\n",
            "* Dana Bantuan Operasional Satuan Pendidikan yang selanjutnya disebut Dana BOSP adalah dana alokasi khusus nonfisik untuk mendukung biaya operasional nonpersonalia bagi Satuan Pendidikan.\n",
            "Top Chunks before post-processing:\n",
            "Chunk 99: (2) Penyampaian laporan realisasi penggunaan Dana BOSP sebagaimana dimaksud pada ayat (1) dilaksanakan paling lambat: a. tanggal 31 Juli tahun anggaran berkenaan untuk laporan realisasi pengunaan Dana BOP PAUD Reguler, Dana BOS Reguler, atau Dana BOP Kesetaraan Reguler tahap I yang ada di Satuan Pendidikan; dan b. tanggal 31 Januari tahun anggaran berikutnya untuk laporan realisasi keseluruhan penggunaan Dana BOSP yang diterima dalam satu tahun anggaran.\n",
            "---\n",
            "Chunk 102: (2) Laporan realisasi keseluruhan sebagaimana dimaksud dalam Pasal 52 dan laporan realisasi minimal 50% (lima puluh persen) penggunaan Dana BOP PAUD Reguler, Dana BOS Reguler, atau Dana BOP Kesetaraan Reguler yang diterima pada tahap I menjadi dasar penyaluran tahap II tahun anggaran berkenaan.\n",
            "---\n",
            "Chunk 105: (2) Pemantauan dan evaluasi sebagaimana dimaksud pada ayat (1) dilakukan terhadap: a. program kebijakan; dan b. pengelolaan Dana BOSP.\n",
            "---\n",
            "Pertanyaan: Kapan laporan realisasi penggunaan Dana BOSP harus disampaikan?\n",
            "Jawaban:\n",
            "* (2) Penyampaian laporan realisasi penggunaan Dana BOSP sebagaimana dimaksud pada ayat (1) dilaksanakan paling lambat: a. tanggal 31 Juli tahun anggaran berkenaan untuk laporan realisasi pengunaan Dana BOP PAUD Reguler, Dana BOS Reguler, atau Dana BOP Kesetaraan Reguler tahap I yang ada di Satuan Pendidikan; dan b. tanggal 31 Januari tahun anggaran berikutnya untuk laporan realisasi keseluruhan penggunaan Dana BOSP yang diterima dalam satu tahun anggaran.\n",
            "* (2) Laporan realisasi keseluruhan sebagaimana dimaksud dalam Pasal 52 dan laporan realisasi minimal 50% (lima puluh persen) penggunaan Dana BOP PAUD Reguler, Dana BOS Reguler, atau Dana BOP Kesetaraan Reguler yang diterima pada tahap I menjadi dasar penyaluran tahap II tahun anggaran berkenaan.\n",
            "* (2) Pemantauan dan evaluasi sebagaimana dimaksud pada ayat (1) dilakukan terhadap: a. program kebijakan; dan b. pengelolaan Dana BOSP.\n"
          ]
        }
      ]
    }
  ]
}