{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4e192aff05c44c2baa49e6b92d6deaa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_befc503258994af8a9b8fe13eb05d1f7",
              "IPY_MODEL_2ed3af2619d14adc8de568f53c1500d9",
              "IPY_MODEL_731518c242b045f39cd5cf8126a0c4b9"
            ],
            "layout": "IPY_MODEL_4e524b8699c847b8825af687524d3ff1"
          }
        },
        "befc503258994af8a9b8fe13eb05d1f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_919bc2108cfe489d833ce6bfee7b36f8",
            "placeholder": "​",
            "style": "IPY_MODEL_cde548b6424041a383691c1871ffd215",
            "value": "Batches: 100%"
          }
        },
        "2ed3af2619d14adc8de568f53c1500d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5b98f0d10cf4630b31914d4c7dba311",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_456e641f054d4c308f1400ba4b67531e",
            "value": 3
          }
        },
        "731518c242b045f39cd5cf8126a0c4b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d78565e6bfaf46fbbf44f5cb2b813b3f",
            "placeholder": "​",
            "style": "IPY_MODEL_59c4c6d828a24f74bb3cceb6b64a3c63",
            "value": " 3/3 [00:25&lt;00:00,  7.41s/it]"
          }
        },
        "4e524b8699c847b8825af687524d3ff1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "919bc2108cfe489d833ce6bfee7b36f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cde548b6424041a383691c1871ffd215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5b98f0d10cf4630b31914d4c7dba311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "456e641f054d4c308f1400ba4b67531e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d78565e6bfaf46fbbf44f5cb2b813b3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59c4c6d828a24f74bb3cceb6b64a3c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "1. This system that relies on semantic similarity. It finds the text in the document that is most similar to the user's question.\n",
        "2. If the user's question doesn't closely resemble the way the information is expressed in the document, the system may not find the correct answer.\n",
        "3. Basic Functionality covers:\n",
        "    * Extract text from PDF documents.\n",
        "    * Perform semantic search to find relevant chunks of text.\n",
        "    * Clean the output to remove unwanted content.\n",
        "    * Provide an answer to the user's question (even if the answer is not always perfect).\n",
        "\n"
      ],
      "metadata": {
        "id": "B9lCgwJuNeHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further Development\n",
        "1. Clarifying Expectation, example :\n",
        "    * Chatbot: \"Dana BOS digunakan untuk membiayai kegiatan operasional sekolah. Apakah Anda ingin mengetahui contoh kegiatan operasional yang dapat dibiayai oleh Dana BOS?\"\n",
        "2. Provide a list of example questions that the user can ask. This shows them the types of questions the chatbot is good at answering. Example:\n",
        "    * Apa saja syarat pengajuan Dana BOS?\n",
        "    * Bagaimana cara melaporkan penggunaan Dana BOS?\n",
        "    * Sebutkan contoh kegiatan yang dapat dibiayai oleh Dana BOS.\n",
        "3. Keyword Suggestions: As the user types their question, suggest relevant keywords that they can include to make their question more specific.\n",
        "4. Intent Recognition (Advanced): Implement a simple intent recognition system. This would analyze the user's question and try to identify the intent behind it (e.g., \"find allowed uses,\" \"find reporting requirements\"). Based on the intent, the chatbot could automatically rephrase the question to be more targeted. This requires more advanced natural language processing techniques.\n",
        "5. Expand the Training Data (If Possible): If you have the ability to add more data to the system, try to find documents that explicitly list the allowed uses of Dana BOS in a clear and structured way. This will make it easier for the semantic search to find the right information.\n",
        "6. Hybrid Approach (Advanced): Consider combining this semantic search approach with a more traditional keyword-based search. If the semantic search fails to find a good answer, the chatbot could fall back to a keyword search to find any relevant documents and present them to the user."
      ],
      "metadata": {
        "id": "1uA6_DXcA7dk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Library"
      ],
      "metadata": {
        "id": "uMo4iKw2NpWv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omTDcRywLsNw",
        "outputId": "829833f5-7818-4377-8ec4-a2c31bf4c476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Collecting sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sastrawi, pymupdf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pymupdf-1.25.4 sastrawi-1.0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install pymupdf nltk sastrawi transformers sentence-transformers\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import fitz\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from google.colab import drive\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Download resource NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Gathering"
      ],
      "metadata": {
        "id": "8SFcHCpwORjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Gathering\n",
        "# ===============================\n",
        "# 1. MOUNT GOOGLE DRIVE & CEK FILES\n",
        "# ===============================\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path ke direktori penyimpanan file PDF\n",
        "pdf_dir = \"/content/drive/My Drive/Colab Notebooks/AI Chatbot Berbasis Regulasi\"\n",
        "\n",
        "# Cek apakah direktori ada\n",
        "if not os.path.exists(pdf_dir):\n",
        "    raise FileNotFoundError(f\"Direktori {pdf_dir} tidak ditemukan! Periksa kembali path-nya.\")\n",
        "else:\n",
        "    print(f\"Direktori ditemukan! Daftar file PDF: {os.listdir(pdf_dir)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUAjLu-hOUiX",
        "outputId": "75e1b0e0-7698-43a6-b6ca-20bbdf2f5577"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Direktori ditemukan! Daftar file PDF: ['Permendikbudriset No. 63 Tahun 2023.pdf', 'Untitled folder', 'extracted_text.json', 'processed_text.json', 'summarized_text.json', 'embeddings.npy', 'chunks.json', 'cleaned_texts.json']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 2. EKSTRAKSI TEKS DARI FILE PDF\n",
        "# ===============================\n",
        "\n",
        "# --- PDF Text Extraction ---\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text(\"text\") + \"\\n\"\n",
        "    return text.strip()\n",
        "\n",
        "pdf_files = [f for f in os.listdir(pdf_dir) if f.endswith(\".pdf\")]\n",
        "pdf_texts = {}\n",
        "\n",
        "for pdf_file in pdf_files:\n",
        "    pdf_path = os.path.join(pdf_dir, pdf_file)\n",
        "    try:\n",
        "        text = extract_text_from_pdf(pdf_path)\n",
        "        pdf_texts[pdf_file] = text\n",
        "        print(f\"Extracted text from: {pdf_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from {pdf_file}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFfX2D-2Qfsf",
        "outputId": "f592dd5d-696f-4dbc-e76b-7502688d8093"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted text from: Permendikbudriset No. 63 Tahun 2023.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Data"
      ],
      "metadata": {
        "id": "AQ-aw2LwUTW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 3. PREPROCESSING TEKS\n",
        "# ===============================\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Cleans text by removing extra newlines and spaces, URLs, specific phrases, and leading numbers.\"\"\"\n",
        "    text = re.sub(r'\\n+', '\\n', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Prevent incorrect splitting: \"Pasal 17.\" -> \"Pasal 17 \"\n",
        "    text = re.sub(r'Pasal (\\d+)\\.\\s', r'Pasal \\1 ', text)\n",
        "    text = re.sub(r'Ayat \\((\\d+[a-z]?)\\)\\.\\s', r'Ayat (\\1) ', text)\n",
        "\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text, flags=re.IGNORECASE)  # Remove URLs\n",
        "    text = re.sub(r'jdih\\.kemdikbud\\.go\\.id', '', text, flags=re.IGNORECASE)  # Remove specific website\n",
        "    text = re.sub(r'OSP untuk operasional -3-', '', text)  # Remove specific phrase\n",
        "    text = re.sub(r'\\b\\d+\\.\\s*', '', text)  # Remove leading numbers like \"5. \"\n",
        "    text = re.sub(r'\\s-\\s\\d+\\s-\\s', ' ', text)  # Remove '- 4 -' pattern\n",
        "\n",
        "    return text\n",
        "\n",
        "cleaned_texts = {pdf: clean_text(text) for pdf, text in pdf_texts.items()}"
      ],
      "metadata": {
        "id": "KHaUz08k3Fbc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 4. CHUNKING TEKS\n",
        "# Splits text into smaller chunks.\n",
        "# ===============================\n",
        "\n",
        "def chunk_text(text, chunk_size=100):\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    for sentence in sentences:\n",
        "        if len(current_chunk) + len(sentence) + 1 <= chunk_size:\n",
        "            current_chunk += sentence + \" \"\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence + \" \"\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "    return chunks\n",
        "\n",
        "all_chunks = []\n",
        "for pdf, text in cleaned_texts.items():\n",
        "    chunks = chunk_text(text)\n",
        "    all_chunks.extend(chunks)\n",
        "\n",
        "print(f\"Total chunks: {len(all_chunks)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka9AdmeJHERa",
        "outputId": "09e97571-62ef-412b-d7c9-3601fc382753"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks: 91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TOKENISASI TEKS"
      ],
      "metadata": {
        "id": "_TRngQpOU0vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 5. TOKENISASI TEKS & EMBEDDING\n",
        "# ===============================\n",
        "\n",
        "# Load Sentence Transformer model (multilingual)\n",
        "model_name = 'paraphrase-multilingual-mpnet-base-v2'  # Replace with the actual model\n",
        "model = SentenceTransformer(model_name)\n",
        "\n",
        "# Generate embeddings for the chunks\n",
        "embeddings = model.encode(all_chunks, show_progress_bar=True)"
      ],
      "metadata": {
        "id": "PL7UayJwU2Za",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4e192aff05c44c2baa49e6b92d6deaa7",
            "befc503258994af8a9b8fe13eb05d1f7",
            "2ed3af2619d14adc8de568f53c1500d9",
            "731518c242b045f39cd5cf8126a0c4b9",
            "4e524b8699c847b8825af687524d3ff1",
            "919bc2108cfe489d833ce6bfee7b36f8",
            "cde548b6424041a383691c1871ffd215",
            "e5b98f0d10cf4630b31914d4c7dba311",
            "456e641f054d4c308f1400ba4b67531e",
            "d78565e6bfaf46fbbf44f5cb2b813b3f",
            "59c4c6d828a24f74bb3cceb6b64a3c63"
          ]
        },
        "outputId": "ae351adc-9a3f-4943-ce4f-45cd05e98cb3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e192aff05c44c2baa49e6b92d6deaa7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SAVING DATA"
      ],
      "metadata": {
        "id": "tNdrpdq1VEse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 6. SAVING DATA\n",
        "# ===============================\n",
        "\n",
        "# Define file paths for saving data\n",
        "embeddings_file = os.path.join(pdf_dir, \"embeddings.npy\")  # Path to save embeddings\n",
        "chunks_file = os.path.join(pdf_dir, \"chunks.json\")  # Path to save chunks\n",
        "cleaned_texts_file = os.path.join(pdf_dir, \"cleaned_texts.json\") # Path to save cleaned texts\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 1. Saving the SentenceTransformer Model (NOT NECESSARY, SEE COMMENTS)\n",
        "# ------------------------------------------------------------------\n",
        "# As discussed, saving the SentenceTransformer model itself is not necessary\n",
        "# because you can simply load it from the Hugging Face Model Hub using the model_name.\n",
        "# Saving the model weights would take up a lot of space and is not required in this case.\n",
        "\n",
        "# --------------------------------------\n",
        "# 2. Saving the Embeddings\n",
        "# --------------------------------------\n",
        "try:\n",
        "    np.save(embeddings_file, embeddings)\n",
        "    print(f\"Embeddings saved to: {embeddings_file}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving embeddings: {e}\")\n",
        "\n",
        "# --------------------------------------\n",
        "# 3. Saving the Chunks of Text\n",
        "# --------------------------------------\n",
        "try:\n",
        "    with open(chunks_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(all_chunks, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"Chunks saved to: {chunks_file}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving chunks: {e}\")\n",
        "\n",
        "# --------------------------------------\n",
        "# 4. Saving the Cleaned PDF Texts\n",
        "# --------------------------------------\n",
        "try:\n",
        "    with open(cleaned_texts_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(cleaned_texts, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"Cleaned texts saved to: {cleaned_texts_file}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving cleaned texts: {e}\")"
      ],
      "metadata": {
        "id": "xCHxhNuqVGav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fddb8fa-68c0-4409-d289-ba30aa27a508"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings saved to: /content/drive/My Drive/Colab Notebooks/AI Chatbot Berbasis Regulasi/embeddings.npy\n",
            "Chunks saved to: /content/drive/My Drive/Colab Notebooks/AI Chatbot Berbasis Regulasi/chunks.json\n",
            "Cleaned texts saved to: /content/drive/My Drive/Colab Notebooks/AI Chatbot Berbasis Regulasi/cleaned_texts.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING"
      ],
      "metadata": {
        "id": "jZ1hT4h7fCl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 7. TESTING CHATBOT\n",
        "# ===============================\n",
        "\n",
        "# --- Question Answering ---\n",
        "def answer_question(question, embeddings, chunks, top_n=3):\n",
        "    question_embedding = model.encode([question])[0]\n",
        "    similarities = cosine_similarity([question_embedding], embeddings)[0]\n",
        "    top_indices = np.argsort(similarities)[::-1][:top_n]\n",
        "\n",
        "    # Debugging: Print the top chunks\n",
        "    print(\"Top Chunks before post-processing:\")\n",
        "    for i in top_indices:\n",
        "        print(f\"Chunk {i}: {chunks[i]}\\n---\")\n",
        "\n",
        "    context = \"\\n\".join([chunks[i] for i in top_indices])\n",
        "\n",
        "    return context\n",
        "\n",
        "def post_process_answer(answer):\n",
        "    # Split the answer into sentences\n",
        "    sentences = sent_tokenize(answer)\n",
        "\n",
        "    # Create a bulleted list from the sentences\n",
        "    bulleted_list = \"\\n\".join([f\"* {sentence.strip()}\" for sentence in sentences])\n",
        "\n",
        "    return bulleted_list\n",
        "\n",
        "# --- Example Usage ---\n",
        "question = \"Jelaskan komponen pembinaan dan pengembangan prestasi?\"  # More focused question\n",
        "raw_answer = answer_question(question, embeddings, all_chunks, top_n=3)\n",
        "processed_answer = post_process_answer(raw_answer)\n",
        "\n",
        "print(f\"Pertanyaan: {question}\")\n",
        "print(f\"Jawaban:\\n{processed_answer}\")\n",
        "\n",
        "# --- Example Usage ---\n",
        "question = \"Transparansi keuangan?\"  # More focused question\n",
        "raw_answer = answer_question(question, embeddings, all_chunks, top_n=3)\n",
        "processed_answer = post_process_answer(raw_answer)\n",
        "\n",
        "print(f\"Pertanyaan: {question}\")\n",
        "print(f\"Jawaban:\\n{processed_answer}\")\n",
        "\n",
        "# --- Example Usage ---\n",
        "question = \"Laporan keuangan dilihat orang lain?\"  # More focused question\n",
        "raw_answer = answer_question(question, embeddings, all_chunks, top_n=3)\n",
        "processed_answer = post_process_answer(raw_answer)\n",
        "\n",
        "print(f\"Pertanyaan: {question}\")\n",
        "print(f\"Jawaban:\\n{processed_answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAASzWSmey1I",
        "outputId": "deb44a47-9ccc-4e56-8c23-c909d249238d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Chunks before post-processing:\n",
            "Chunk 50: (4) Bagi sekolah yang memiliki prestasi yang ditetapkan sebagai sekolah pengimbas, selain komponen penggunaan Dana BOS Kinerja sebagaimana dimaksud pada ayat (3), juga harus melaksanakan komponen pembinaan dan pengembangan prestasi.\n",
            "---\n",
            "Chunk 49: -8-  (3) Komponen penggunaan Dana BOS Kinerja bagi sekolah yang memiliki prestasi sebagaimana dimaksud pada ayat (1) huruf b meliputi: a. asesmen dan pemetaan talenta; b. pelatihan dan pengembangan talenta; dan/atau c. pengembangan manajemen dan ekosistem.\n",
            "---\n",
            "Chunk 82: d. Pembinaan dan pengembangan prestasi satuan pendidikan melalui program pengimbasan untuk sekolah pengimbas merupakan komponen yang digunakan untuk pembiayaan kegiatan pembinaan dan pengembangan kepada satuan pendidikan yang belum berprestasi, seperti: 1) pengembangan kapasitas sumber daya manusia talenta sekolah imbas; 2) kegiatan pemberian pendampingan dan layanan konsultasi pelaksanaan pengembangan program manajemen talenta bagi sekolah imbas; 3) pengembangan talenta sekolah imbas melalui kemitraan; 4) penyelenggaraan kompetisi lokal antar sekolah bersama sekolah imbas; dan/atau 5) kegiatan lain yang relevan dalam rangka pembinaan dan pengembangan prestasi sekolah imbas.\n",
            "---\n",
            "Pertanyaan: Jelaskan komponen pembinaan dan pengembangan prestasi?\n",
            "Jawaban:\n",
            "* (4) Bagi sekolah yang memiliki prestasi yang ditetapkan sebagai sekolah pengimbas, selain komponen penggunaan Dana BOS Kinerja sebagaimana dimaksud pada ayat (3), juga harus melaksanakan komponen pembinaan dan pengembangan prestasi.\n",
            "* -8-  (3) Komponen penggunaan Dana BOS Kinerja bagi sekolah yang memiliki prestasi sebagaimana dimaksud pada ayat (1) huruf b meliputi: a. asesmen dan pemetaan talenta; b. pelatihan dan pengembangan talenta; dan/atau c. pengembangan manajemen dan ekosistem.\n",
            "* d. Pembinaan dan pengembangan prestasi satuan pendidikan melalui program pengimbasan untuk sekolah pengimbas merupakan komponen yang digunakan untuk pembiayaan kegiatan pembinaan dan pengembangan kepada satuan pendidikan yang belum berprestasi, seperti: 1) pengembangan kapasitas sumber daya manusia talenta sekolah imbas; 2) kegiatan pemberian pendampingan dan layanan konsultasi pelaksanaan pengembangan program manajemen talenta bagi sekolah imbas; 3) pengembangan talenta sekolah imbas melalui kemitraan; 4) penyelenggaraan kompetisi lokal antar sekolah bersama sekolah imbas; dan/atau 5) kegiatan lain yang relevan dalam rangka pembinaan dan pengembangan prestasi sekolah imbas.\n",
            "Top Chunks before post-processing:\n",
            "Chunk 60: (2) Pemantauan dan evaluasi sebagaimana dimaksud pada ayat (1) dilakukan terhadap: a. program kebijakan; dan b. pengelolaan Dana BOSP.\n",
            "---\n",
            "Chunk 55: (2) Penyampaian laporan realisasi penggunaan Dana BOSP sebagaimana dimaksud pada ayat (1) dilaksanakan paling lambat: a. tanggal 31 Juli tahun anggaran berkenaan untuk laporan realisasi pengunaan Dana BOP PAUD Reguler, Dana BOS Reguler, atau Dana BOP Kesetaraan Reguler tahap I yang ada di Satuan Pendidikan; dan b. tanggal 31 Januari tahun anggaran berikutnya untuk laporan realisasi keseluruhan penggunaan Dana BOSP yang diterima dalam satu tahun anggaran.\n",
            "---\n",
            "Chunk 58: (2) Laporan realisasi keseluruhan sebagaimana dimaksud dalam Pasal 52 dan laporan realisasi minimal 50% (lima puluh persen) penggunaan Dana BOP PAUD Reguler, Dana BOS Reguler, atau Dana BOP Kesetaraan Reguler yang diterima pada tahap I menjadi dasar penyaluran tahap II tahun anggaran berkenaan.\n",
            "---\n",
            "Pertanyaan: Transparansi keuangan?\n",
            "Jawaban:\n",
            "* (2) Pemantauan dan evaluasi sebagaimana dimaksud pada ayat (1) dilakukan terhadap: a. program kebijakan; dan b. pengelolaan Dana BOSP.\n",
            "* (2) Penyampaian laporan realisasi penggunaan Dana BOSP sebagaimana dimaksud pada ayat (1) dilaksanakan paling lambat: a. tanggal 31 Juli tahun anggaran berkenaan untuk laporan realisasi pengunaan Dana BOP PAUD Reguler, Dana BOS Reguler, atau Dana BOP Kesetaraan Reguler tahap I yang ada di Satuan Pendidikan; dan b. tanggal 31 Januari tahun anggaran berikutnya untuk laporan realisasi keseluruhan penggunaan Dana BOSP yang diterima dalam satu tahun anggaran.\n",
            "* (2) Laporan realisasi keseluruhan sebagaimana dimaksud dalam Pasal 52 dan laporan realisasi minimal 50% (lima puluh persen) penggunaan Dana BOP PAUD Reguler, Dana BOS Reguler, atau Dana BOP Kesetaraan Reguler yang diterima pada tahap I menjadi dasar penyaluran tahap II tahun anggaran berkenaan.\n",
            "Top Chunks before post-processing:\n",
            "Chunk 60: (2) Pemantauan dan evaluasi sebagaimana dimaksud pada ayat (1) dilakukan terhadap: a. program kebijakan; dan b. pengelolaan Dana BOSP.\n",
            "---\n",
            "Chunk 55: (2) Penyampaian laporan realisasi penggunaan Dana BOSP sebagaimana dimaksud pada ayat (1) dilaksanakan paling lambat: a. tanggal 31 Juli tahun anggaran berkenaan untuk laporan realisasi pengunaan Dana BOP PAUD Reguler, Dana BOS Reguler, atau Dana BOP Kesetaraan Reguler tahap I yang ada di Satuan Pendidikan; dan b. tanggal 31 Januari tahun anggaran berikutnya untuk laporan realisasi keseluruhan penggunaan Dana BOSP yang diterima dalam satu tahun anggaran.\n",
            "---\n",
            "Chunk 58: (2) Laporan realisasi keseluruhan sebagaimana dimaksud dalam Pasal 52 dan laporan realisasi minimal 50% (lima puluh persen) penggunaan Dana BOP PAUD Reguler, Dana BOS Reguler, atau Dana BOP Kesetaraan Reguler yang diterima pada tahap I menjadi dasar penyaluran tahap II tahun anggaran berkenaan.\n",
            "---\n",
            "Pertanyaan: Laporan keuangan dilihat orang lain?\n",
            "Jawaban:\n",
            "* (2) Pemantauan dan evaluasi sebagaimana dimaksud pada ayat (1) dilakukan terhadap: a. program kebijakan; dan b. pengelolaan Dana BOSP.\n",
            "* (2) Penyampaian laporan realisasi penggunaan Dana BOSP sebagaimana dimaksud pada ayat (1) dilaksanakan paling lambat: a. tanggal 31 Juli tahun anggaran berkenaan untuk laporan realisasi pengunaan Dana BOP PAUD Reguler, Dana BOS Reguler, atau Dana BOP Kesetaraan Reguler tahap I yang ada di Satuan Pendidikan; dan b. tanggal 31 Januari tahun anggaran berikutnya untuk laporan realisasi keseluruhan penggunaan Dana BOSP yang diterima dalam satu tahun anggaran.\n",
            "* (2) Laporan realisasi keseluruhan sebagaimana dimaksud dalam Pasal 52 dan laporan realisasi minimal 50% (lima puluh persen) penggunaan Dana BOP PAUD Reguler, Dana BOS Reguler, atau Dana BOP Kesetaraan Reguler yang diterima pada tahap I menjadi dasar penyaluran tahap II tahun anggaran berkenaan.\n"
          ]
        }
      ]
    }
  ]
}